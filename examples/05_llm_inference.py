"""
This is a conceptual example of the Level 3 (Generative)
inference engine. This would require the 'google-generativeai'
package and an API key.

Do not run this file directly. It is for demonstration.
"""

import percipio
# from percipio.llm_engine import set_api_key

# set_api_key("YOUR_GEMINI_API_KEY")

# --- Problem: Highly ambiguous, unstructured data ---
# No regex can reliably parse all these different name formats.
data = [
    "Smith, John A.",
    "Dr. Jane B. Doe",
    "Michael O'Connor III",
    "Prof. P. K. Srinivasan",
    "Invalid Name",
    "David Lee"
]

print("--- Inferring ambiguous 'PersonName' data ---")
# 'default' engine (regex/stats) would fail or return 'String'.
# We specify engine='llm' to enable generative inference.
schema = percipio.infer(data, engine='llm')

# --- What 'percipio' would do behind the scenes ---
# 1. 'default' engine fails (confidence < 50%).
# 2. 'llm' engine is activated.
# 3. It sends a prompt to Gemini, like:
#    "Analyze these data samples: [samples...].
#     What is the single semantic type (e.g., 'Email', 'Address')?
#     Respond in JSON: {"semantic_type": "..."}"
# 4. Gemini responds: {"semantic_type": "PersonName"}
# 5. 'percipio' asks a follow-up:
#    "Write a single Python function 'parse(item: str) -> dict | None'
#     that can parse data like ['samples...'] into a dictionary
#     of its components (e.g., 'title', 'first', 'last', 'suffix').
#     Return *only* the Python code for the function."
# 6. Gemini returns the Python 'def parse(...):' code.
# 7. 'percipio' dynamically creates a new 'DynamicPersonNameType' class,
#    using the 'parse' code from Gemini as its '_clean_item' method.
# 8. This new, dynamic type is returned as the 'schema'.

# --- The result ---
print(f"Inferred Type: {schema.name}") # e.g., "Dynamic_PersonName"
print(f"Valid: {schema.stats.valid_count} / {schema.stats.total_count}\n")

print("--- Cleaning with dynamically-generated parser ---")
# This .clean() method is now using the code generated by the AI
clean_data = schema.clean(data)

for item in clean_data:
    print(item)

# --- Expected Output ---
# {'title': '', 'first': 'John', 'middle': 'A.', 'last': 'Smith', 'suffix': '', 'raw': 'Smith, John A.'}
# {'title': 'Dr.', 'first': 'Jane', 'middle': 'B.', 'last': 'Doe', 'suffix': '', 'raw': 'Dr. Jane B. Doe'}
# {'title': '', 'first': 'Michael', 'middle': '', 'last': "O'Connor", 'suffix': 'III', 'raw': "Michael O'Connor III"}
# {'title': 'Prof.', 'first': 'P.', 'middle': 'K.', 'last': 'Srinivasan', 'suffix': '', 'raw': 'Prof. P. K. Srinivasan'}
# None
# {'title': '', 'first': 'David', 'middle': '', 'last': 'Lee', 'suffix': '', 'raw': 'David Lee'}
